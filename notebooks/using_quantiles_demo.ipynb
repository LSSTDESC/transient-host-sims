{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbed7dc6-d8c4-4076-a2ba-9aa4125e230c",
   "metadata": {},
   "source": [
    "# Using ELAsTiCC $p(z | photometry)$\n",
    "\n",
    "_Alex Malz (GCCL@RUB --> CMU)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1bc95-5728-46ee-9ac2-c3deac4d7742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed = 42\n",
    "import scipy.integrate as spi\n",
    "import scipy.stats as sps\n",
    "import sys\n",
    "eps = sys.float_info.epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c05c22-aa52-4620-a0ac-d1d586afc60a",
   "metadata": {},
   "source": [
    "## Reading ELAsTiCC photo-$z$ data\n",
    "\n",
    "Note: this whole section will have to be changed to the actual training set file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554e5d5-dbac-4620-b1f1-9dab56ed708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_heads = {'SNIa': 10,\n",
    "            'SNII': 10, \n",
    "            'SNIbc': 10, \n",
    "            'UNMATCHED_KN_SHIFT': 10,\n",
    "            'UNMATCHED_COSMODC2': 9}\n",
    "# next time, do something clever to infer the header lengths, e.g.\n",
    "# hl_head = int(os.system(f\"zcat {hl_path} | cat -n | sed -n '/VARNAMES/ {{ p; q }}'  | awk '{{print $1-1}}'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c156cd0-69fa-4069-ab7b-9c1e71277fde",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's pick one hostlib for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc23239-6d7a-48fa-9ee9-c037d06623fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_one = 0\n",
    "which_hl = list(hl_heads.keys())[pick_one]\n",
    "hl_path = '/global/cfs/cdirs/lsst/groups/TD/SN/SNANA/SURVEYS/LSST/ROOT/PLASTICC_DEV/HOSTLIB/zquants/'+which_hl+'_dummy_pz.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39fa30-fa95-4799-9982-1baaaf4d4b71",
   "metadata": {},
   "source": [
    "**WARNING: slow!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a175c-bd3e-4a6a-9bb7-86ec1742a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(hl_path, delimiter=' ', header=0)\n",
    "nhost = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3eefd-6026-4a0a-ab2a-8e3da7da23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936c06e-c17d-4aeb-8cfe-a487858b035c",
   "metadata": {},
   "source": [
    "Do a sanity check on the point estimates, if truth is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc80f1-0286-434a-9875-014edd748aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['ZTRUE'], df['ZPHOT_Q050'], s=0.1, alpha=0.1, c=df['P_ZPHOT'])\n",
    "plt.xlabel('$z_{true}$')\n",
    "plt.ylabel('$z_{median}$')\n",
    "plt.plot([0., 3.], [0., 3.], c='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf0866-6c16-430a-a0c2-da483e0ff61c",
   "metadata": {},
   "source": [
    "## Reviewing quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bebefb-bf04-45bd-91ce-d48be94a68f2",
   "metadata": {},
   "source": [
    "Recall that the quantiles $z_{q}$ are the redshifts at which $q = CDF(z_{q}) = \\int_{0}^{z_{q}} p(z) dz$.\n",
    "\n",
    "The quantiles used should probably be stored somewhere other than in the column names, but here they are anyway.\n",
    "\n",
    "Note that we could have saved ourselves one float by replacing the redshifts where $CDF=0$ and $CDF=1$ with $p(z_{q})$ for any of the saved quantiles $q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a5f55-aa48-4566-a8e5-99644cefbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = np.linspace(0., 1., 11)\n",
    "quants[0] += eps\n",
    "quants[-1] -= eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e067aea-e2b4-4256-b00d-f6b1a7d37f19",
   "metadata": {},
   "source": [
    "Let's isolate that information from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd261f1-8ffa-4ece-8cd9-c2d81099c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantlabs = ['ZPHOT_Q000', 'ZPHOT_Q010', 'ZPHOT_Q020', 'ZPHOT_Q030', 'ZPHOT_Q040', 'ZPHOT_Q050', 'ZPHOT_Q060', 'ZPHOT_Q070', 'ZPHOT_Q080', 'ZPHOT_Q090', 'ZPHOT_Q100']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ca48f-84e6-4ce8-9b0f-706f7f7c6b2d",
   "metadata": {},
   "source": [
    "And let's pick just one galaxy for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c82163-8130-44e1-913d-af9514c2eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one = random.sample(range(nhost), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef256ff-4f16-495a-858a-bdce66f81328",
   "metadata": {},
   "outputs": [],
   "source": [
    "zq_vals = df[quantlabs].loc[show_one].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355719f-c203-4620-8330-1c7cb5cc18ea",
   "metadata": {},
   "source": [
    "## Reconstructing PDFs from quantiles\n",
    "\n",
    "The goal is now to recover $p(z)$ from the $(z, CDF(z))$ pairs.\n",
    "This demonstrates the reconstruction algorithm from [ye olde qp](https://github.com/aimalz/qp), which was originally written in Python 2, and though it runs without error in Python 3, changes to numpy array broadcasting may produce results inconsistent with [Malz & Marshall+ 2017](http://stacks.iop.org/1538-3881/156/i=1/a=35).\n",
    "The basic idea, however, is robust.\n",
    "We can safely assume $p(z_{000}) = 0$ and $p(z_{100}) = 0$ for $CDF(z_{000}) = 0$ and $CDF(z_{100}) = 1$ to anchor the endpoints, and by definition of the quantiles, the area under the curve between $z_{q_{i}}$ and $z_{q_{i+1}}$ is equal to $q_{i+1} - q_{i}$.\n",
    "By linear interpolation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26428166-8a35-45dd-b0fd-4f8aa54cd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = quants\n",
    "z = zq_vals\n",
    "\n",
    "derivative = (q[1:] - q[:-1]) / (z[1:] - z[:-1])\n",
    "derivative = np.insert(derivative, 0, eps)\n",
    "derivative = np.append(derivative, eps)\n",
    "def inside(xf):\n",
    "    nx = len(xf)\n",
    "    yf = np.ones(nx) * eps\n",
    "    for n in range(nx):\n",
    "        i = bisect.bisect_left(z, xf[n])\n",
    "        yf[n] = derivative[i]\n",
    "    return(yf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cac791-9350-44d9-a512-dab1e35c3d06",
   "metadata": {},
   "source": [
    "Let's try a few grids upon which to evaluate reconstructed PDFs, testing the following:\n",
    "1. `log`: the grid from which they were originally reduced\n",
    "2. `lin`: a linearly spaced grid with the same granularity\n",
    "3. `spa`: a very coarse grid\n",
    "4. `den`: an excessively dense grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea9e659-1b01-4416-a2a3-ace7d7ba7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "zgrid = {}\n",
    "zgrid['log'] = np.logspace(-3., np.log10(3.), 300)\n",
    "zgrid['lin'] = np.arange(0., 3.01, 0.01)\n",
    "zgrid['spa'] = np.linspace(0., 3., 100)#zq_vals\n",
    "zgrid['den'] = np.linspace(0., 3., 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5c95e-af05-4963-8a7f-0bf35965a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pdf = {}\n",
    "for key, val in zgrid.items():\n",
    "    eval_pdf[key] = inside(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b7465-8f43-4e0a-bb96-31997896dbe3",
   "metadata": {},
   "source": [
    "Let's visualize this one to see how much it looks like a Gaussian PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57330b5a-522b-436d-822c-226670e00609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(df[quantlabs].loc[show_one].values[0], -1, 1, linestyle='--', color='k')\n",
    "# plt.xlim(obs_locs[plot_one][0]-5*sigma*(1+obs_locs[plot_one][0]), \n",
    "#          obs_locs[plot_one][0]+5*sigma*(1+obs_locs[plot_one][0]))\n",
    "plt.xlim(df['ZPHOT_Q000'].loc[show_one].values[0]-0.01, df['ZPHOT_Q100'].loc[show_one].values[0]+0.01)\n",
    "for key in zgrid.keys():\n",
    "    plt.plot(zgrid[key], eval_pdf[key], '-o', markersize=3, label=key, alpha=0.75)\n",
    "plt.text(df['ZPHOT_Q000'].loc[show_one].values[0], 5, str(df['GALID'].loc[show_one].values[0]))\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$p(z)$')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e95953-c811-4775-84e9-af3368a676f8",
   "metadata": {},
   "source": [
    "## Performing sanity checks\n",
    "\n",
    "On a sufficiently fine grid, the recovered PDF should integrate to 1.\n",
    "We can and should manually renormalize if the adherence to the normalization condition is insufficient.\n",
    "Here are a few ways to check that integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e59194-5008-4a93-b735-77291c1019da",
   "metadata": {},
   "outputs": [],
   "source": [
    "trap_int = {}\n",
    "for key, val in zgrid.items():\n",
    "    print(key)\n",
    "    print('trapezoid-rule integral: '+str(spi.trapezoid(eval_pdf[key], zgrid[key])))\n",
    "    print('average integral at histogram midpoints: '+str(np.sum((eval_pdf[key][1:]+eval_pdf[key][:-1])/2.*(zgrid[key][1:]-zgrid[key][:-1]))))\n",
    "    print('histogram approximation: '+str(np.sum(eval_pdf[key][:-1] * (zgrid[key][1:]-zgrid[key][:-1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712f424-02bf-4e9a-aa79-d476e5638609",
   "metadata": {},
   "source": [
    "Another way to reconstruct PDFs from quantiles would use any one $p(z_{q})$ corresponding to saved quantile $q$ as an anchor, eliminating the need for the anchors at $CDF = 0$ and $CDF = 1$.\n",
    "However, in the name of expediency, we leave it as an exercise for the reader.\n",
    "Just kidding!\n",
    "I'll take care of it soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614925f-b043-4813-bbaa-bee7de45896d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELAsTiCC",
   "language": "python",
   "name": "ve3_elasticc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
