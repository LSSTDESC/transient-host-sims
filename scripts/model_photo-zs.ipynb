{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbed7dc6-d8c4-4076-a2ba-9aa4125e230c",
   "metadata": {},
   "source": [
    "# producing $p(z | photometry)$ for ELAsTiCC\n",
    "\n",
    "_Alex Malz (GCCL@RUB)_\n",
    "\n",
    "The goal here is to generate mock photo-$z$ posteriors for host galaxies. \n",
    "Ideally, we want them to contain no assumptions not present in the $p(z, photometry$ space from which they were drawn.\n",
    "That's not really feasible. . .\n",
    "\n",
    "TODO: explain why we can't do this\n",
    "\n",
    "The next best thing to do is to aim for realistic complexity and make assumptions as similar to those of the underlying $p(z, photometry)$ model, by using [`pzflow`](https://github.com/jfcrenshaw/pzflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34026799-f3ba-4662-86d2-db2710d1ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GCRCatalogs\n",
    "# from GCRCatalogs import cosmodc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1bc95-5728-46ee-9ac2-c3deac4d7742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6844fcf-3c0c-4311-bd97-f38efbe076a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pzflow\n",
    "from pzflow import Flow\n",
    "from pzflow.bijectors import Chain, ColorTransform, InvSoftplus, StandardScaler, RollingSplineCoupling, ShiftBounds\n",
    "from pzflow.distributions import Uniform, Joint, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498562b-1faf-430e-9568-40bf382826a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qp\n",
    "# help(qp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add85763-d062-41e4-9903-4891e6b370ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail\n",
    "# from rail.creation import Creator, engines\n",
    "from rail.creation.degradation import LSSTErrorModel\n",
    "\n",
    "# awkwardly the rail dev branch is broken such that creators don't exist but degraders still do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3df5b-966b-4ff4-b22f-ef33f5343de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "mpl.rcParams['mathtext.rm'] = 'serif'\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['font.serif'] = 'DejaVu Serif'\n",
    "# mpl.rcParams['axes.titlesize'] = 16\n",
    "# mpl.rcParams['axes.labelsize'] = 14\n",
    "# mpl.rcParams['savefig.dpi'] = 250\n",
    "# mpl.rcParams['savefig.format'] = 'pdf'\n",
    "# mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"dejavuserif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c156cd0-69fa-4069-ab7b-9c1e71277fde",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's pick one hostlib for now.\n",
    "\n",
    "TODO: loop through hostlibs later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a175c-bd3e-4a6a-9bb7-86ec1742a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_path = '/global/cfs/cdirs/desc-td/SN/SNANA/SURVEYS/LSST/ROOT/PLASTICC_DEV/HOSTLIB/TEMP_HOSTLIBS/SNIa_GHOST_PHOTOZ.HOSTLIB'\n",
    "# skip 26lines\n",
    "df = pd.read_csv(hl_path, skiprows=25, delimiter=' ', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773cb5f2-95af-4320-b4b5-cc0597f46936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca634a-1e43-496f-a548-9b47827836b5",
   "metadata": {},
   "source": [
    "`pzflow` needs a grid upon which to evaluate redshift posteriors. \n",
    "We use a fine grid now but will compress it for the alert stream later.\n",
    "And we can check what the redshift distribution of the hostlib is.\n",
    "\n",
    "TODO: investigate the prevalence at $z \\sim 3$ and maybe ask to re-run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c8661-72c1-4aca-8b63-e1ca4ac29dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zgrid = np.logspace(-3., np.log10(3.), 300)\n",
    "plt.hist(df['ZTRUE'], bins=zgrid);\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('number of galaxies')\n",
    "plt.title('hostlib redshift distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cedf85b-7339-4484-b38e-77498917cc77",
   "metadata": {},
   "source": [
    "John Franklin Crenshaw (UW) had a pre-trained normalizing flow trained on a representative set of $10^{6}$ LSST-DESC DC2 galaxies, so I'm using that for now.\n",
    "\n",
    "TODO: explain things that would have been better but didn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec50f3-dc21-45af-aa81-e123ed2d6ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow = Flow(file='../data_files/model_photo-zs_sharp10_splbin2_epoch30_flow.pkl')#'desc-dc2-K=16.pkl')#Flow(file='../data_files/pzflow_dc2small_nofilter_div1000.pkl')\n",
    "flow = Flow(file='../data_files/model_photo-zs_sharp5_splbin8_epoch100_flow.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf7c8b-d4a3-4cb7-aa83-fd01dba9f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.conditional_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef2770-626a-4c5a-9d2a-bbfdc4e2b4eb",
   "metadata": {},
   "source": [
    "We trim and rename the hostlib data to match the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae15385-1546-42a1-b454-70da6dfe8218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hl_df = df.rename(columns={'Y_obs':'y', \n",
    "#                    'r_obs':'r', \n",
    "#                    'u_obs':'u', \n",
    "#                    'g_obs':'g', \n",
    "#                    'z_obs':'z', \n",
    "#                    'i_obs':'i', \n",
    "#                    'ZTRUE':'redshift'})[['redshift', 'u', 'g', 'r', 'i', 'z', 'y']]\n",
    "hl_df = df.rename(columns={'Y_obs':'y', \n",
    "                   'r_obs':'r', \n",
    "                   'u_obs':'u', \n",
    "                   'g_obs':'g', \n",
    "                   'z_obs':'z', \n",
    "                   'i_obs':'i', \n",
    "                    'ZTRUE':'redshift'})[['redshift', 'u', 'g', 'r', 'i', 'z', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40f900-02f0-4d67-afc4-71e57651386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d13fe-a188-43a9-9b51-f9ecef6ac086",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_df_colors = hl_df.copy()\n",
    "quantities = hl_df.columns\n",
    "for i in range(len(quantities)-2):\n",
    "    hl_df_colors[quantities[i+1]+'-'+quantities[i+2]] = hl_df[quantities[i+1]] -hl_df[quantities[i+2]]\n",
    "hl_df_colors = hl_df_colors.drop(columns = quantities)\n",
    "hl_df_colors['r'] = hl_df['r']\n",
    "hl_df_colors['redshift'] = hl_df['redshift']\n",
    "hl_df = hl_df_colors[['redshift', 'u-g', 'g-r', 'r-i', 'i-z', 'z-y', 'r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33bf0d-c9bf-4783-a34b-d3c7adf86b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb98555-68b2-46bb-b1d6-9b4a9298bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hl_named = hl_df.rename(columns={'mag_true_y_lsst':'y', \n",
    "#                    'mag_true_r_lsst':'r', \n",
    "#                    'mag_true_u_lsst':'u', \n",
    "#                    'mag_true_g_lsst':'g', \n",
    "#                    'mag_true_z_lsst':'z', \n",
    "#                    'mag_true_i_lsst':'i',\n",
    "#                     'ZTRUE':'redshift'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977acf43-5352-412a-8da3-c7080941b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hl_named.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6699c-d95a-4eff-93d8-9e286e86f3d7",
   "metadata": {},
   "source": [
    "Let's compare the distribution of data between the model and the hostlib.\n",
    "Note how different they are! This is a very non-representative sample, so we expect pretty awful photo-$z$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68001fb-3bfe-4175-9b91-84bf2ad055eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvis = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ac90c-2739-47d3-8c16-f022532d136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = flow.sample(nvis, seed=0)\n",
    "\n",
    "# fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "# ranges = [(-0.1,2.4), (19.5,33), (19,32), (19,29), (19,29), (19,28), (19,28)]\n",
    "\n",
    "# corner.corner(samples, fig=fig, color='r', bins=20, range=ranges, hist_bin_factor=2, data_kwargs={'ms':3}, contour_kwargs={'linewidths':2}, label='pz model')\n",
    "\n",
    "# corner.corner(hl_df[:nvis], fig=fig, bins=20, range=ranges, hist_bin_factor=2, color='b', data_kwargs={'ms':3}, show_titles=True, label='hostlib');\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1712674-a4fe-4240-a62d-a44aaf678bf6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# samples = flow.sample(10000, seed=0)\n",
    "# print(samples.columns)\n",
    "\n",
    "# for quality in ['redshift', 'u', 'g', 'r', 'i', 'z', 'y']:\n",
    "#     plt.hist(samples[quality], bins=100, alpha=0.5, density=True, label='pz model samples');\n",
    "#     plt.hist(hl_df[quality], bins=100, alpha=0.5, density=True, label='hostlib samples')\n",
    "#     plt.title(quality)\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e198ca-82f2-495a-9a30-b80d08542c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow.conditional_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72097f3e-e981-49e0-9118-5824dbd9b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5676d8-73e4-4373-a8d8-288f31e89fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow.latent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767dd5ce-1c26-4945-8014-8ce0cf2cf76e",
   "metadata": {},
   "source": [
    "Now we can evaluate some posteriors and check that they look as expected.\n",
    "They're way too narrow because there's no error model (and maybe the normalizing flow had too many knots).\n",
    "\n",
    "TODO: use RAIL to convolve with error model before evaluating, or make a new flow with fewer knots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8335b-bac2-4005-be93-29665b23abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_z = flow.posterior(hl_df[['u-g', 'g-r', 'r-i', 'i-z', 'z-y', 'r']][:nvis], column='redshift', grid=zgrid)\n",
    "# flow_z = flow.posterior(hl_df[['mag_true_u_lsst-mag_true_g_lsst',\n",
    "#  'mag_true_g_lsst-mag_true_r_lsst',\n",
    "#  'mag_true_r_lsst-mag_true_i_lsst',\n",
    "#  'mag_true_i_lsst-mag_true_z_lsst',\n",
    "#  'mag_true_z_lsst-mag_true_y_lsst',\n",
    "#  'mag_true_r_lsst']][:nvis], column='redshift', grid=zgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d49e42-77ec-4226-a676-8ce86d74c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = flow_z\n",
    "\n",
    "idx = np.arange(0, nvis, 99)\n",
    "fig, axes = plt.subplots(1,len(idx),figsize=(2*len(idx),2), dpi=100)\n",
    "for i,ax in zip(idx, axes):\n",
    "    true_z = hl_df['redshift'][i]\n",
    "    ax.axvline(true_z, 0, 1, c=\"C3\",\n",
    "               label='True z')\n",
    "    ax.plot(zgrid, pdfs[i])\n",
    "    ax.set(xlabel=\"redshift\",\n",
    "           # xticks=[0,0.5,1,1.5,2],\n",
    "           yticks=[])\n",
    "# axes[0].legend()\n",
    "axes[0].set(ylabel='$p(z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfd284-6163-4130-b267-c76cc60ee4b5",
   "metadata": {},
   "source": [
    "The point estimates are really weird here and need to be investigated. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a9c13-f5e4-4d72-867a-16d66475bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hl_df['redshift'][:nvis], zgrid[np.argmax(flow_z, axis=1)], s=1, c='k')\n",
    "plt.plot([0., 3.], [0., 3.], c='r')#[min(hl_scaled['ZTRUE'][:nvis]), max(hl_scaled['ZTRUE'][:nvis])], [min(hl_scaled['ZTRUE'][:nvis]), max(hl_scaled['ZTRUE'][:nvis])], c='r')\n",
    "plt.xlabel(r'$z_{true}$')\n",
    "plt.ylabel(r'$z_{mode}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed659f2d-1286-4f43-86d5-5f89eae7d8ac",
   "metadata": {},
   "source": [
    "Anyway, let's cut to the important part, the compression of the posteriors using `qp`.\n",
    "\n",
    "First, make a qp ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205bb42-b14d-4846-ade1-b3f981e909f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_pdfs = qp.Ensemble(qp.interp, data=dict(xvals=zgrid, yvals=flow_z, check_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb442a0-7a31-49ff-a1b1-6a51b551e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(0, nvis, 99)\n",
    "fig, axes = plt.subplots(1,len(idx),figsize=(2*len(idx),2), dpi=100)\n",
    "for i,ax in zip(idx, axes):\n",
    "    true_z = hl_df['redshift'][i]\n",
    "    ax.axvline(true_z, 0, 1, c=\"C3\",\n",
    "               label='True z')\n",
    "    ax.plot(zgrid, in_pdfs.pdf(zgrid)[i])\n",
    "    ax.set(xlabel=\"redshift\",\n",
    "           # xticks=[0,0.5,1,1.5,2],\n",
    "           yticks=[])\n",
    "    ax.set_xlim(0, 0.25)\n",
    "# axes[0].legend()\n",
    "axes[0].set(ylabel='$p(z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5cb2b-7506-47cb-8f8d-368a7413e1d2",
   "metadata": {},
   "source": [
    "Then choose quantile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54cbe64-85fb-4dff-af5e-07f500f4cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = np.linspace(0., 1., 11)[1:]\n",
    "print(quants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242976d1-ea5e-4422-8914-2c46509bbf48",
   "metadata": {},
   "source": [
    "convert ensemble to quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536124ee-5626-485e-959d-f67ba97c61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pdfs = in_pdfs.convert_to(qp.quant_piecewise_gen, quants=quants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45d263-104f-440f-afa3-8a96a03c7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pdfs_eval = out_pdfs.pdf(zgrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4c211-fa14-4f60-86ce-50bd066d413d",
   "metadata": {},
   "source": [
    "TODO: fix qp quantile reconstruction bug!\n",
    "\n",
    "Issue is that input PDFs aren't normalized, even when converted to qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cde067-4afa-4dba-9219-f47f5ad239c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(0, nvis, 99)\n",
    "fig, axes = plt.subplots(1,len(idx),figsize=(2*len(idx),2), dpi=100)\n",
    "for i,ax in zip(idx, axes):\n",
    "    true_z = hl_df['redshift'][i]\n",
    "    ax.axvline(true_z, 0, 1, c=\"C3\",\n",
    "               label='True z')\n",
    "    ax.plot(zgrid, out_pdfs_eval[i])\n",
    "    ax.set(xlabel=\"redshift\",\n",
    "           # xticks=[0,0.5,1,1.5,2],\n",
    "           yticks=[])\n",
    "# axes[0].legend()\n",
    "    ax.set_xlim(0, 0.25)\n",
    "axes[0].set(ylabel='$p(z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf0e71-cf38-4dae-9eda-acc1f24acd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/global/u2/a/aimalz/ve3_elasticc/lib/python3.9/site-packages/qp/quant_pdf.py', 'r') as f:\n",
    "    for l in f:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddca10d-8317-42f4-84b6-93f39771a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ppfs = out_pdfs.ppf(quants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db73bc-5700-444b-b1fa-f977016610a9",
   "metadata": {},
   "source": [
    "TODO: save these to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8947338b-370b-4d1f-9764-b42b06a93239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quant_to_grid(qp_quant, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc5660-3a24-47f4-b6fa-fcfc109bf6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = qp.plotting.plot_native(out_pdfs[1], xlim=(0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52197f6-9678-481e-a853-a5c97fe51fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zs = uncompressed * df['ZTRUE'].std() + df['ZTRUE'].mean()\n",
    "# for quality in ['logmass', 'logSFRtot', 'mag_true_u_lsst', 'mag_true_g_lsst', 'mag_true_r_lsst', 'mag_true_i_lsst', 'mag_true_z_lsst', 'mag_true_y_lsst']:\n",
    "#     data_scaled[quality] = (data[quality]-data[quality].mean())/data[quality].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09811fe6-6d01-4c4e-a2f3-412abd088db0",
   "metadata": {},
   "source": [
    "# scratch below here, please ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24552d30-3f96-49cc-bc9c-9d8cca623ae9",
   "metadata": {},
   "source": [
    "why are the true posteriors so crazy compared to the true redshifts? maybe because of rescaling over all dimensions for the flow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5401564-91d8-44cd-b88a-5b84b74f2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmap = plt.get_cmap('tab10')\n",
    "# maxpdfs = 5\n",
    "# for i in range(maxpdfs):\n",
    "#     plt.plot(zgrid, flow_z[i], color=cmap(i/maxpdfs))\n",
    "#     plt.vlines(hl_scaled['ZTRUE'][i], 0., max(flow_z[i]), color=cmap(i/maxpdfs))\n",
    "# plt.xlabel(r'$z$')\n",
    "# plt.ylabel(r'$p(z)$')\n",
    "# plt.semilogx()\n",
    "# plt.show()\n",
    "# for i in range(maxpdfs):\n",
    "#     plt.plot(zgrid, flow_z[i], color=cmap(i/maxpdfs))\n",
    "#     plt.vlines(hl_scaled['ZTRUE'][i], 0., max(flow_z[i]), color=cmap(i/maxpdfs))\n",
    "# plt.xlabel(r'$z$')\n",
    "# plt.ylabel(r'$p(z)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37d231-a879-49bf-a833-6ebbc59e9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flow_samps = flow.sample(1, conditions=hl_scaled[['mag_true_y_lsst',\n",
    "# #  'mag_true_r_lsst',\n",
    "# #  'mag_true_u_lsst',\n",
    "# #  'mag_true_g_lsst',\n",
    "# #  'mag_true_z_lsst',\n",
    "# #  'mag_true_i_lsst',\n",
    "# #  'logSFRtot',\n",
    "# #  'logmass']][:nvis], seed=0)\n",
    "# flow_samps = flow.sample(1, conditions=hl_named[['u', 'g', 'r', 'i', 'z', 'y']][:nvis], seed=0)\n",
    "# plt.hist(flow_samps['redshift'], bins=zgrid, alpha=0.5, density=True, label='pz model samples');\n",
    "# plt.hist(hl_df['ZTRUE'][:nvis], bins=zgrid, alpha=0.5, density=True, label='hostlib samples');\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e313b63-739c-4ff1-9f3e-c87128ae0aa4",
   "metadata": {},
   "source": [
    "Why do these distributions still not even come close to matching? The flow should have coverage over the hostlib range but doesn't. The redshifts might be normalized somehow, too?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d8953-5a9c-4f3b-90fe-886dc12dfdad",
   "metadata": {},
   "source": [
    "renormalize\n",
    "\n",
    "Note DC2 SFRs are Msol/Gyr but hostlibs are log10 Msol/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ccc8df-4cb2-441e-a145-302a205df371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties = {}\n",
    "# properties['logmass'] = ( 6.6518884, 0.96087)\n",
    "# properties['logSFRtot'] = ( 6.24535, 1.6989895)\n",
    "# properties['mag_true_u_lsst'] = ( 30.86386, 3.0129747)\n",
    "# properties['mag_true_g_lsst'] = ( 29.790226, 2.088292)\n",
    "# properties['mag_true_r_lsst'] = ( 29.342756, 1.87558)\n",
    "# properties['mag_true_i_lsst'] = ( 29.0863, 1.9085665)\n",
    "# properties['mag_true_z_lsst'] = ( 28.870272, 1.9486268)\n",
    "# properties['mag_true_y_lsst'] = ( 28.658136, 1.9420407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99bf3d-fb66-4630-a1e9-0904952c68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_normed(data, properties):\n",
    "#     data_out = data.copy()\n",
    "#     for quality in properties.keys():\n",
    "#         data_out[quality] = (data[quality] - properties[quality][0]) / properties[quality][1]\n",
    "#     return data_out\n",
    "\n",
    "# def do_un_norm(data, properties):\n",
    "#     data_out = data.copy()\n",
    "#     for quality in properties.keys():\n",
    "#         data_out[quality] = data[quality] * properties[quality][1] + properties[quality][0]\n",
    "#     return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234fed9-4375-4bd9-b544-0444dfcc88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data = hl_df.copy()\n",
    "# # for quality in ['logmass', 'logSFRtot', 'mag_true_u_lsst', 'mag_true_g_lsst', 'mag_true_r_lsst', 'mag_true_i_lsst', 'mag_true_z_lsst', 'mag_true_y_lsst']:\n",
    "# #     plt.hist(data[quality], bins=100)\n",
    "# #     plt.title(quality+' pre-normalization')\n",
    "# #     plt.show()\n",
    "# hl_scaled = make_normed(hl_df, properties)\n",
    "# # data.copy()\n",
    "# # for quality in ['logmass', 'logSFRtot', 'mag_true_u_lsst', 'mag_true_g_lsst', 'mag_true_r_lsst', 'mag_true_i_lsst', 'mag_true_z_lsst', 'mag_true_y_lsst']:\n",
    "# #     data_scaled[quality] = (data[quality]-properties[quality][0])/properties[quality][1]\n",
    "# # for quality in ['redshift']:#['logmass', 'logSFRtot', 'mag_true_u_lsst', 'mag_true_g_lsst', 'mag_true_r_lsst', 'mag_true_i_lsst', 'mag_true_z_lsst', 'mag_true_y_lsst']:\n",
    "# #     plt.hist(data_scaled[quality], bins=100)\n",
    "# #     plt.title(quality+' post-normalization')\n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c1fde8-0562-42e9-9f04-20c88e6fdf86",
   "metadata": {},
   "source": [
    "make a NF from DC2? No, too slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd174ce0-91a3-446b-8ede-31f2f5422038",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cosmo = GCRCatalogs.load_catalog(\"cosmoDC2_v1.1.4_small\")\n",
    "# quantities = ['redshift', 'mag_true_u_lsst', 'mag_true_g_lsst', 'mag_true_r_lsst', 'mag_true_i_lsst', 'mag_true_z_lsst', 'mag_true_y_lsst']#, 'stellar_mass', 'totalStarFormationRate']\n",
    "\n",
    "# print(\"Reading CosmoDC2 small catalog\")\n",
    "# data = cosmo.get_quantities(quantities)\n",
    "# print(\"Catalog read.\")\n",
    "# data = pd.DataFrame(data)\n",
    "# # data['logSFRtot'] = onp.log10(data['totalStarFormationRate'])\n",
    "# # data['logmass']   = onp.log10(data['stellar_mass'])\n",
    "# # data.drop(columns=['totalStarFormationRate', 'stellar_mass'], inplace=True)\n",
    "\n",
    "# # plt.figure(figsize=(10,7))\n",
    "# # plt.plot(data['redshift'].sample(n=100000, random_state=1), (data['mag_true_g_lsst'] - data['mag_true_r_lsst']).sample(n=100000, random_state=1), 'o', ms=0.1)\n",
    "# # plt.xlabel(\"DC2 Redshift\")\n",
    "# # plt.ylabel(r\"$g-r$\")\n",
    "# # # plt.savefig(\"../plots/ogdc2_zvcolor_gr.png\")\n",
    "# # plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660e70b-0317-4f43-b1fc-bb9d63ac1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_scaled[['mag_true_y_lsst',\n",
    "#  'mag_true_r_lsst',\n",
    "#  'mag_true_u_lsst',\n",
    "#  'mag_true_g_lsst',\n",
    "#  'mag_true_z_lsst',\n",
    "#  'mag_true_i_lsst',\n",
    "#  'logSFRtot',\n",
    "#  'logmass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5708a-3bce-4301-a961-d688f95e8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_samps = flow.sample(1, data_scaled[['mag_true_y_lsst',\n",
    "#  'mag_true_r_lsst',\n",
    "#  'mag_true_u_lsst',\n",
    "#  'mag_true_g_lsst',\n",
    "#  'mag_true_z_lsst',\n",
    "#  'mag_true_i_lsst',\n",
    "#  'logSFRtot',\n",
    "#  'logmass']][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efd3e3-a67a-4929-b84b-0e7ce2f57a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_samps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485391a-ea17-4eca-9a84-b4edf333b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(test_samps['redshift'] - flow_df['ZTRUE'][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8166111-ff99-4150-a677-7ed1da0a3214",
   "metadata": {},
   "source": [
    "something has gone wrong here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b867a-c20a-4c82-9b8d-a70f8e581284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELAsTiCC",
   "language": "python",
   "name": "ve3_elasticc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
